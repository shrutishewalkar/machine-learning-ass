{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee45c6a4-6ba4-445d-8e66-373db8036f85",
   "metadata": {},
   "source": [
    "Q1 What is random forest regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56432c6-1ef6-4619-aebb-aad285e22ea7",
   "metadata": {},
   "source": [
    "Random forest regresssor is a supervised learning algorithm that uses ensemble learning method for regression.it combines multiple decision trees to create a powerful model that can predict numberical values or continuous variables.\n",
    "the random forest regressor is a popular algorithm used in a various field , including finance healthcare, marketing among others, for prediction tasks such as stock price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc40d5-4876-4d24-bd59-0cbc95cbab80",
   "metadata": {},
   "source": [
    "Q2 how does random forest regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86cae0-f498-4f70-aeda-f7b3bcfc2aa6",
   "metadata": {},
   "source": [
    "Random forest regressor reduces the risk of overfitting in several ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03115c4a-941a-4ee5-be4b-ba51908a4e5d",
   "metadata": {},
   "source": [
    "1. Bootstrap sampling: the algorithm uses bootstap sampling . where it randomly selected sample with replacement from the training dataset to create a subset of the data to train each decision tree.this procress creates multiple trees that have different training data to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1616f5-a680-4004-addd-40f5edff1fd1",
   "metadata": {},
   "source": [
    "2. Feature randomness: the algorithm also select a random subset of feature for each decision tree. by combining the prediction of feature, which reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a852b-0f36-4b6f-8898-66de1e963294",
   "metadata": {},
   "source": [
    "3. Ensemble method: random forest regressor is an ensemble method that combines the predictions of multiple decision trees., by combining the prediction of multiple trees, the algorithm reduce the variance and bias of the overall model, which reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58b08f-2bb1-43fa-b7f8-2196f61d5837",
   "metadata": {},
   "source": [
    "4. Pruning: the algoritm prunes the decision tree by limiting thier depth, which prevents them from fitting too closely to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b4f99-62a3-41cb-bebc-d072b6f3fcab",
   "metadata": {},
   "source": [
    "Q3 how does random forest regressor aggregate the prediction of multiple decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5528ac-96ac-4fab-ad80-9580f5927a2e",
   "metadata": {},
   "source": [
    "the random forest regressor aggregates the prediction of multiple decision trees by taking the average of their outputs. when a new data point is presented to the model each decision tree in the forest predict an output value,which is a numerical value for regressor problems.the final prediction is then calculate as the average of all the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d168d92-d250-4be9-9432-c1f55843a90e",
   "metadata": {},
   "source": [
    "Q4 what are the hyperparameters of random forest regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e952a-ee66-4337-98e4-fdf5c16650fc",
   "metadata": {},
   "source": [
    "the hyperparameter of random forest regressor are:\n",
    "\n",
    "    1. n_estimators:it is the number of decision tress in the forest.\n",
    "    \n",
    "    2. max_features: it is the maximum number of features that the algorithm considered each split. this hyperparameters control the randomness of model and can help prevent overfitting .\n",
    "    \n",
    "    3.max_depth: it is the maximum depth of each decision tree. increasing the depth of th trees allows the model to capture more comple relationshipin the data, but also increse the risk of overfitting.\n",
    "    \n",
    "    4.min_sample_split: it is the minimum number of sample required to split an internal nodes.\n",
    "    \n",
    "    5. min_samples_leaf: it is the minimum number of sample required to to be at a leaf node.\n",
    "    \n",
    "    6. bootstrap: it is a boolean parameter that indicades whether bootstrap sampling is used when building the decision trees.\n",
    "    \n",
    "    7. random_state: it i a seed value for the random number generator used by the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f9ba6-40eb-4e01-8f90-2d01816638ae",
   "metadata": {},
   "source": [
    "Q5 what is the difference between random forest regressor and decision tree regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98bc0c-db70-4830-853a-ec536b1d3054",
   "metadata": {},
   "source": [
    "Adecision tree combines some decisions , whereas a random forest combines several decision trees. thus, it is a long process, yet slow. whereas , a decision tree is fast and operates easily on large data sets, espicially the linear one. the random forest model need rigorous training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f9124-8e80-4906-be79-e36bb20f1f1e",
   "metadata": {},
   "source": [
    "Q6 what is advantage and disadvantage of random forest regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb37dd-8668-4d6f-bb2f-db59da155365",
   "metadata": {},
   "source": [
    "Advantages:it can perform both regression and classification tasks. a random forest produces good predictions that can be unserstood easily. it can handel large datasets efficiently. the random forest algorithm provides a higher level of accuracy  in predicting outcomes over the decision tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad596a8-87cf-4533-800b-7f7b31682c70",
   "metadata": {},
   "source": [
    "Disadvantages:\n",
    "increased accuracy requires more trees.\n",
    "more trees slow down model. \n",
    "cants describe relationship within data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886974dd-77c1-46a0-9a6b-3d3927b90d8e",
   "metadata": {},
   "source": [
    "Q7:what is the output of random forest regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb89ab-a227-40ef-bf91-0652459e739a",
   "metadata": {},
   "source": [
    "the output of the random forest regressor is a continuous numerical value, wich represented the predicted value of the target variable for given input of features.the  predicted value is the average of the predictions made by each decision tree in the forest. this outputcan be used for various regression problems such as predicting house prices, stock prices, or sales figur ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d1853-b534-44bb-b135-af1bc3b9699e",
   "metadata": {},
   "source": [
    "Q8 can random forest regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48988495-321d-462f-94f3-dd6f20515796",
   "metadata": {},
   "source": [
    "yes, randomforest regressor can also be used for classification tasks by using modified version called random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69ede7-4335-4af0-9eb1-292e7ecf6df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
